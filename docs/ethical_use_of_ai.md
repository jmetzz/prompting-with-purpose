!!! tip ""
    > "With great power comes great responsibility." _Spider Man_

In [Chapter 5, Results Verification](results_verification.md), you learned how to verify if an AI’s output is accurate using the `SENSE` framework. But truth is only part of the equation. Ethics is about something else: What is the _right_ thing to do when using AI—especially when others are affected?

This chapter introduces two practical frameworks—__FAIR__ and __RISK__—to help you think clearly and act responsibly in real-world situations.

---

## Why Ethics Matters

AI tools are powerful and persuasive. They can generate convincing text, images, or code instantly. But with great power comes responsibility:

- Are you unintentionally spreading biased or unfair information?
- Are you presenting AI work as your own?
- Are you respecting others’ privacy?
- Are you making a decision that could impact someone’s rights or well-being?

This chapter won’t give you all the answers—but it will help you ask better questions.

---

## The Bigger Picture: Societal Debates

The frameworks in this chapter are practical tools for individual use, but it's important to understand the broader societal conversations happening around AI. Critical perspectives argue that the rapid adoption of AI comes with significant risks that are worth considering:

- __Impact on Knowledge and Trust:__ Some critics use the metaphor of an "epistemic carcinogen" to describe how AI could erode our collective ability to trust information by flooding our world with plausible but synthetic content.
- __Hidden Costs:__ The creation of powerful AI models involves hidden costs, including significant environmental impact, the use of precarious human labor to filter toxic content, and the scraping of copyrighted data without creators' consent.
- __The Future of Work:__ There is an ongoing debate about whether AI will primarily augment human capabilities or replace human labor, raising important questions about the future of our economy and society.

Acknowledging these profound challenges is part of using AI responsibly. It helps frame why the hands-on, critical approach in this course is so important.

---

## Key Risks to Watch Out For

🤖 __Bias and Discrimination__

AI tools can reflect and amplify societal biases (e.g., gender, race, class).

Example: An AI that writes job ads may reinforce stereotypes if trained on biased data.

📉 __Misinformation and Hallucinations__

AI can make up facts or present incorrect data confidently.

Example: An AI-generated article includes fake statistics or citations.

🔐 __Privacy and Security__

Sharing personal or sensitive data with AI tools (even by accident) can be risky.

Example: Asking AI to summarize a confidential work email might leak details.

🧰 __Misuse and Over-reliance__

AI is a tool—not a replacement for human responsibility.

Example: Copying AI answers without checking can lead to errors or legal issues.

Sources: Montreal Declaration for Responsible AI, OpenAI on Hallucinations

---

## Everyday Scenarios to Think About

- Generating a social media post using AI? Be clear if it’s AI-generated.
- Writing marketing content? Double-check for biased or exclusionary language.
- Using someone’s personal story in training data? Get permission first.
- Using AI to screen job candidates? Be aware of bias and legal risks.
- Getting AI help to summarize sensitive documents? Consider confidentiality.
- Asking AI for life advice? Use judgment, not just output.

---

## The FAIR Framework

> Generating and publishing content

When using AI to write, generate, or publish something, run it through the __FAIR__ test:

- __F – Fairness__: Is this output free of harmful stereotypes or biased assumptions?
- __A – Attribution__: Are you being transparent about what was generated by AI?
- __I – Impact__: Could this cause harm, confusion, or unintended consequences?
- __R – Rights__: Does this respect people’s privacy, consent, and intellectual property?

---

## The RISK Framework

> Making Decisions

Use this checklist when the AI is influencing a decision, judgment, or recommendation:

- __R – Relevance__: Is the AI’s input actually relevant and suited to this decision?
- __I – Integrity__: Are you keeping your own standards for accuracy, fairness, and truth?
- __S – Sensitivity__: Is the topic sensitive (e.g., health, identity, legal)? Proceed with care.
- __K – Knowledge Gap__: Are you assuming the AI knows more than it really does?

---

## Practical Reflection Prompts

- What’s the _worst misuse_ of this AI output I can imagine? How do I guard against it?
- Would I be comfortable showing this to the person it’s about?
- Am I hiding the fact that AI helped me?

---

## Learn More

- See the [Results Verification](results_verification.md) chapter for how to check facts.
- If you’re working in a professional context, check your organization’s AI or data policy.
- Refer to external codes like:
  - [Mozilla: Trustworthy Artificial Intelligence](https://foundation.mozilla.org/en/internet-health/trustworthy-artificial-intelligence/)
  - [OECD AI Principles](https://oecd.ai/en/ai-principles)
  - [UNESCO AI Ethics Recommendation](https://unesdoc.unesco.org/ark:/48223/pf0000380455)
  - [Montreal Declaration](https://www.montrealdeclaration-responsibleai.com/)
  - [OpenAI Usage Policies](https://openai.com/policies/usage-policies)
- For deeper reading on the critical perspectives discussed in this chapter, consider these sources:
  - [An open letter from educators who refuse the call to adopt GenAI in education](https://openletter.earth/an-open-letter-from-educators-who-refuse-the-call-to-adopt-genai-in-education-cb4aee75)
  - [GenAI is an epistemic carcinogen](https://link.springer.com/article/10.1007/s00146-025-02537-x)
  - [Chatbots Can Trigger a Mental Health Crisis. What to Know About "AI Psychosis"](https://time.com/7307589/ai-psychosis-chatgpt-mental-health/)
